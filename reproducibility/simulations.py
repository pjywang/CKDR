import os, sys
sys.path.insert(0, os.path.abspath('..'))

import numpy as np
import torch
import pickle

# For Rand index after clustering
from sklearn.metrics import adjusted_rand_score
from functions import KQuantiles

# Import necessary training functions
from functions import ckdr_cv, ckdr_cv_parallel
from functions import train_ckdr

# Parallel processing
from joblib import Parallel, delayed

from reproducibility.other_methods.rpy2setup import setup_r_environment
from reproducibility.prediction_comparison import _get_fold

MASTER_SEED = 20241225


def logistic_normal(n, p, cov="auto", rho=0.2, zero_cut=0.5, seed=None):
    """
    Generate a random n x p matrix from a logistic-normal distribution as described in Lin et al. (2014).
    Zeros are artificially generated by replacing the smallest 50% (zero_cut) values with a zero.
    Then, the rows are normalized to sum to 1, making it a valid probability simplex.

    Parameters
    ----------
    n: int, number of samples
    p: int, number of variables
    cov: string or np.ndarray, indicates what covariance matrix to use.
        If "auto" then we generate a covariance matrix with rho^|i-j|, where i and j are indices of variables.
        If "id" then we use the identity matrix I_p.
        If a numpy array is provided, it should be a valid covariance matrix of shape (p, p).
    zero_cut: Number in [0, 1]. If zero_cut = 0.2, make the smallest 20% values zero
    seed: int or np.random.RandomState, random seed for reproducibility

    Returns
    -------
    X: n x p numpy array, each row is a sampled compositional vector

    """

    Rand = seed if isinstance(seed, np.random.RandomState) else np.random.RandomState(seed=seed)
    
    # Mean vector is set to zero
    theta = np.zeros(p)

    if cov == "auto":
        # near variables are correlated, further away are almost uncorrelated
        cov = np.array([[rho ** np.abs(i - j) for j in range(p)] for i in range(p)])
    elif cov == "id":
        cov = np.eye(p)
    else:
        cov = np.array(cov)
        assert cov.shape == (p, p), "Specified covariance matrix must be of shape (p, p)."

    # n x p MVN matrix
    W = Rand.multivariate_normal(theta, cov, n)

    # logistic transform onto the open simplex
    # Caveat: numerical issues may occur if the input covariance matrix is very large
    X = np.exp(W)
    threshold = np.quantile(X, zero_cut)
    X[X < threshold] = 0

    # Normalization
    X = X / np.sum(X, 1)[:, None]  

    return X


############################################
### Functions to generate Y variables
############################################

def Y1(X, sigma=.1, seed=0):
    n, p = X.shape
    cut1 = p // 5
    cut2 = p // 2
    Z1 = X[:, :cut1].sum(1)
    Z2 = X[:, cut1:cut2].sum(1)
    Z3 = X[:, cut2:].sum(1)

    Y = -5 * Z1 + 0 * Z2 + 4 * Z3

    Rand = seed if isinstance(seed, np.random.RandomState) else np.random.RandomState(seed=seed)
    Y = Y + Rand.normal(0, sigma, X.shape[0])
    return Y


def Y2(X, sigma=.1, seed=0):
    n, p = X.shape
    cut1 = p // 5
    cut2 = p // 2
    Z1 = X[:, :cut1].sum(1)
    Z2 = X[:, cut1:cut2].sum(1)
    Z3 = X[:, cut2:].sum(1)

    Y = 3 * np.cos(Z1) + Z3 ** 2 / (Z2 + 0.01)

    Rand = seed if isinstance(seed, np.random.RandomState) else np.random.RandomState(seed=seed)
    Y = Y + Rand.normal(0, sigma, X.shape[0])
    return Y


def Y3(X, sigma=.1, seed=0):
    n, p = X.shape
    cut1 = p // 5
    cut2 = p // 2
    Z1 = X[:, :cut1].sum(1)
    Z2 = X[:, cut1:cut2].sum(1)
    Z3 = X[:, cut2:].sum(1)

    Y = 5 * Z2 - 3 * Z3

    Rand = seed if isinstance(seed, np.random.RandomState) else np.random.RandomState(seed=seed)
    Y = np.sign(Y + Rand.normal(0, sigma, X.shape[0]))
    return Y


def Y4(X, sigma=.1, seed=0):
    n, p = X.shape
    cut1 = p // 5
    cut2 = p // 2
    Z1 = X[:, :cut1].sum(1)
    Z2 = X[:, cut1:cut2].sum(1)
    Z3 = X[:, cut2:].sum(1)

    Y = 3 * Z1 ** 2 + 4 * Z2 ** 2 - 2 * Z3 ** 2

    Rand = seed if isinstance(seed, np.random.RandomState) else np.random.RandomState(seed=seed)
    Y = np.sign(Y + Rand.normal(0, sigma, X.shape[0]))
    return Y


#########################################################
### True central compositional/amalgamation subspaces
#########################################################

def get_true(p):
    """ 
    Generate a true vector of length p that indicates the true cluster membership, indicating the true compositional amalgamation.
    """
    true = np.zeros(p)
    cut1 = p // 5
    cut2 = p // 2
    true[cut1:cut2] = 1
    true[cut2:] = 2
    return true


def true_mat(p, Y_func):
    """
    A true matrix A that generates the true central compositional subspace, which depends on the Y function.
    """

    if Y_func.__name__ in ("Y1", "Y3"):
        target_dim = 2
    else:
        target_dim = 3

    A = np.zeros((target_dim, p))
    cut1 = p // 5
    cut2 = p // 2

    if target_dim == 3:
        # Matrix that generates the true central compositional (amalgamation) subspace
        A[0, :cut1] = 1
        A[1, cut1:cut2] = 1
        A[2, cut2:] = 1
    elif target_dim == 2:
        if Y_func.__name__ == "Y1":
            A[0, :cut1] = 1
            A[1, cut2:] = 1
            A[0, cut1:cut2] = 4/9
            A[1, cut1:cut2] = 5/9
        elif Y_func.__name__ == "Y3":
            A[0, cut2:] = 1
            A[1, cut1:cut2] = 1
            A[0, :cut1] = 5/8
            A[1, :cut1] = 3/8
    return A


##########################################################
### Subspace distance functions
##########################################################

def subsp_proj(A):
    """
    Projection matrix to the row space of A: A^T(AA^T)^{\dagger}A

    param A: np.array
    """
    return A.T @ np.linalg.pinv(A @ A.T) @ A


def subsp_dist(A, B):
    """
    Chordal distance between the row spaces of A and B
    Computes sqrt{(\|P_A - P_B\|_F^2 - |rank(A) - rank(B)|) / (2 * min(rank(A), rank(B)))}

    This is a valid distance even if A and B have different row ranks.
    See Ye et al. (2016) for details.
    """
    diff = subsp_proj(A) - subsp_proj(B)
    rk_A = np.linalg.matrix_rank(A)
    rk_B = np.linalg.matrix_rank(B)

    sq_frob = np.sum(diff ** 2)

    sq_dist = (sq_frob - abs(rk_A - rk_B)) / (2 * min(rk_A, rk_B))

    return np.sqrt(sq_dist)


###########################################################
### Repeat training after cross-validation
###########################################################

def repeat_cv(n, p, Y_func, X_func, m=None, Y_noise=0.1,
              distfun=subsp_dist, njobs=100, reps=100, foldername="subsp_convergence",
              load=False, seed=None
               ):

    # One of the true CSDR matrices
    true_matrix = true_mat(p, Y_func)

    # True cluster membership indicator of the columns
    true_cluster = get_true(p)

    # Set the target dimension
    if m is None:
        # Well-specified case where m is the true dimension of the central compositional subspace
        target_dim = true_matrix.shape[0]
    elif m == "cv":
        # Cross-validated case where m is the best dimension found in cross-validation
        target_dim = None
    else:
        # User-specified case
        target_dim = m

    # Type of Y variable; binary or continuous
    type_Y = "binary" if Y_func in [Y3, Y4] else None

    # Case-wise seed control
    if isinstance(seed, int):
        Y_idx = ("Y1", "Y2", "Y3", "Y4").index(Y_func.__name__) + 1
        targ = target_dim if target_dim is not None else 100
        seed = seed - (n * Y_idx * targ)

    if load:
        # load the parameters from the previously trained model
        with open("./results/simulation/{}/param_op_{}_{}_{}{}.pickle".format(foldername, n, Y_func.__name__, X_func.__name__, m), "rb") as f:
            params = pickle.load(f)
        
    else:
        # Find the best parameters using cross-validation at the first run
        RS = np.random.RandomState(seed)
        X = X_func(n, p, seed=RS)
        Y = Y_func(X, sigma=Y_noise, seed=RS)
        dim_list = [target_dim] if target_dim is not None else [3, 4, 5, 6, 7]
        result = ckdr_cv_parallel(X, Y, type_Y=type_Y,
                                  folds=5, verbose=True,
                                    dim_list=dim_list,
                                    epsilon_list=[0.001, 0.01],
                                    sigma_list=np.geomspace(1/2, 2., 5), med=True, 
                                    n_jobs=min(50, njobs), seed=RS,
                                    refit=False)
        
        params = result["parameters"]

        # Save the parameters
        with open("./results/simulation/{}/param_op_{}_{}_{}{}.pickle".format(foldername, n, Y_func.__name__, X_func.__name__, m), "wb") as f:
            pickle.dump(params, f) 

    # Selected parameters for the CKDR model
    epsilon, sigma, target_dim = params["epsilon"], params["sigma_Z"], params["target_dim"]

    def process(i):
        """
        Function to process each repetition of the simulation.
        """
        RS = np.random.RandomState(seed + i)
        X = X_func(n=n, p=p, seed=RS)
        Y = Y_func(X, sigma=Y_noise, seed=RS)

        # Train the CKDR model with the best parameters found in cross-validation
        P, obj_hist, model = train_ckdr(X, Y, target_dim, type_Y, epsilon=epsilon, sigma=sigma, verbose=False, seed=RS)
        
        # Clustering the columns of P on the simplex
        clus = KQuantiles(n_clusters=3, random_state=RS, verbose=False)
        clus.fit(P.numpy().T)

        # ARI to compare the true cluster membership with the predicted clusters
        ari = adjusted_rand_score(true_cluster, clus.clusters)

        # Calculate the distance between the true central compositional subspace and the estimated row space of P
        dist = distfun(true_matrix, P.numpy())
        
        # Rank of the estimated subspace
        rank = np.linalg.matrix_rank(P.numpy())

        return dist, ari, rank

    results = np.array(Parallel(n_jobs=njobs, verbose=2)(delayed(process)(i) for i in range(reps)))

    print("n={}, p={}, Y={}, X={}".format(n, p, Y_func.__name__, X_func.__name__))
    print("Mean distance: {:.4f}".format(results.mean(0)[0]), "+/-", "SE: {:.4f}".format(results.std(0)[0] / np.sqrt(reps)))
    print("Mean ARI: {:.4f}".format(results.mean(0)[1]), "+/-", "SE: {:.4f}".format(results.std(0)[1] / np.sqrt(reps)))
    with open("./results/simulation/{}/op_{}_{}_{}{}.pickle".format(foldername, n, Y_func.__name__, X_func.__name__, m), "wb") as f:
        pickle.dump(results, f)

    return results



#############################################
### Repeat amalgam method for comparison
#############################################


def repeat_amalgam(n, p, Y_func, Y_noise=0.1,
                   njobs=100, reps=100, seed=None,
                   foldername="amalgam_results"):
    """
    Repeat applying the amalgam method on simulated data.

    n: Sample size
    p: Number of variables
    Y_func: Response function (Y3 or Y4)
    Y_noise: Noise level for the response variable
    distfun: Function to compute the distance between subspaces
    reps: Number of repetitions
    seed: Random seed for reproducibility
    """
    
    # Set up R environment (uncomment the next two lines if needed)
    # from reproducibility.other_methods.rpy2setup import setup_r_environment
    # setup_r_environment()

    # One of the true CSDR matrices
    true_matrix = true_mat(p, Y_func)

    # Set the well-specified target number of amalgams (favoring amalgam)
    target_dim = 3

    # Case-wise seed control
    if isinstance(seed, int):
        Y_idx = ("Y1", "Y2", "Y3", "Y4").index(Y_func.__name__) + 1
        seed = seed - (n * Y_idx * target_dim)

    # Train amalgam model
    def process(i):
        """
        Function to process each repetition of the simulation.
        """
        import rpy2.robjects as ro
        from rpy2.robjects.packages import importr
        from rpy2.robjects import numpy2ri

        # Activate numpy2ri conversion
        numpy2ri.activate()

        # Check if amalgam package is available, install if not
        try:
            amalgam = importr('amalgam')
            print("Package 'amalgam' is already installed.")
        except:
            print("Package 'amalgam' not found. Installing...")
            devtools = importr('devtools')
            devtools.install_github('tpq/amalgam')
            amalgam = importr('amalgam')
            print("Package 'amalgam' installed successfully.")

        inner_seed = seed + i if seed is not None else None

        RS = np.random.RandomState(inner_seed)
        X = logistic_normal(n=n, p=p, seed=RS)
        Y = Y_func(X, sigma=Y_noise, seed=RS)
        X = zero_replacement(X, method="min", val=0.5)
        
        # Convert numpy arrays to R objects
        Xr = ro.conversion.py2rpy(X)
        Yr = ro.conversion.py2rpy(Y)

        # Yr as type "factor"
        Yr = ro.FactorVector(Yr)

        # Run the amalgam method
        A = amalgam.amalgam(x=Xr, n_amalgams=target_dim, maxiter=10000,
                            objective=amalgam.objective_maxRDA,
                            z=Yr, asSLR=False, shrink=False, 
                            monitor=False # this passes the ga function in the R package GA; suppress verbose output
                            )

        W = np.array(A.rx('weights')[0]).T

        return W

    result_arrays = np.array(Parallel(n_jobs=njobs, verbose=2)(delayed(process)(i) for i in range(reps)))
    
    with open("./results/simulation/{}/op_{}_{}.pickle".format(foldername, n, Y_func.__name__), "wb") as f:
        pickle.dump(result_arrays, f)

    return result_arrays


################################################
### Prediction repetition functions
################################################

def repeat_prediction(n, p, Y_func, X_func, m=None, Y_noise=0.1,
                      njobs=100, reps=100, foldername="predictions",
                      load=True, seed=None
                      ):
    """ 
    Repeat training the CKDR method for prediction performance assessment.
    
    n: Sample size
    p: Number of variables
    Y_func: Response function (Y1, Y2, Y3, or Y4)
    X_func: Covariate function (logistic_normal)
    m: Target dimension of the central compositional subspace; if None, use the true dimension
       If "cv", cross-validate the best dimension
    Y_noise: Noise level for the response variable
    njobs: Number of parallel jobs to run
    reps: Number of repetitions
    foldername: Folder name to save the results
    load: If True, load the parameters from a previously trained model
          We will use the parameters selected from the previous run of `repeat_cv` (subspace distance assessment)
    seed: Random seed for reproducibility
    """

    # Set the target dimension
    if m is None:
        # Well-specified case where m is the true dimension of the central compositional subspace
        target_dim = 2 if Y_func in [Y1, Y3] else 3
    elif m == "cv":
        # Cross-validated case where m is the best dimension found in cross-validation
        target_dim = None
    else:
        # User-specified case
        target_dim = m

    # Type of Y variable; binary or continuous
    type_Y = "binary" if Y_func in [Y3, Y4] else None

    # Case-wise seed control
    if isinstance(seed, int):
        Y_idx = ("Y1", "Y2", "Y3", "Y4").index(Y_func.__name__) + 1
        targ = target_dim if target_dim is not None else 100
        seed = seed - (n * Y_idx * targ)

    if load:
        # load the parameters from the previously trained model
        with open("./results/simulation/convergence2/param_op_{}_{}_logistic_normal{}.pickle".format(n, Y_func.__name__, m), "rb") as f:
            params = pickle.load(f)
        
    else:
        # Find the best parameters using cross-validation at the first run
        RS = np.random.RandomState(seed)
        X = X_func(n, p, seed=RS)
        Y = Y_func(X, sigma=Y_noise, seed=RS)
        dim_list = [target_dim] if target_dim is not None else [3, 4, 5, 6, 7]
        result = ckdr_cv_parallel(X, Y, type_Y=type_Y,
                                  folds=5, verbose=True,
                                    dim_list=dim_list,
                                    epsilon_list=[0.001, 0.01],
                                    sigma_list=np.geomspace(1/2, 2., 5), 
                                    n_jobs=min(50, njobs), seed=RS,
                                    refit=False)
        
        params = result["parameters"]

        # Save the parameters
        with open("./results/simulation/{}/param_{}_{}_{}.pickle".format(foldername, n, Y_func.__name__, m), "wb") as f:
            pickle.dump(params, f)

    # Selected parameters for the CKDR model
    epsilon, sigma, target_dim = params["epsilon"], params["sigma_Z"], params["target_dim"]
    print("Selected parameters: epsilon={}, sigma={}, target_dim={}".format(epsilon, sigma, target_dim))

    def process(i):
        """
        Function to process each repetition of the simulation.
        """
        RS = np.random.RandomState(seed + i)
        X = X_func(n=n, p=p, seed=RS)
        Y = Y_func(X, sigma=Y_noise, seed=RS)

        # Generate a new independent test set for prediction
        X_test = X_func(n=n, p=p, seed=RS)  
        Y_test = Y_func(X_test, sigma=Y_noise, seed=RS)     

        # Train the CKDR model with the best parameters found in cross-validation
        P, obj_hist, model = train_ckdr(X, Y, target_dim, type_Y, epsilon=epsilon, sigma=sigma, verbose=False, seed=RS)

        # Process the test data
        X_test_p, Y_test_p = model.test_processing(X_test, Y_test)

        # Predictions (Yhat)
        predictions = model.predict(P, sigma, epsilon, X_test_p)

        # Detach and convert to numpy for convenience
        if torch.is_tensor(predictions):
            predictions = predictions.detach().cpu().numpy()
        if torch.is_tensor(Y_test_p):
            Y_test_p = Y_test_p.detach().cpu().numpy()

        pred_measure = None
        if type_Y == "binary":
            # Test accuracy for binary classification
            Y_test_p = Y_test_p.ravel() # flatten to 1D for comparison
            pred_measure = np.mean(predictions == Y_test_p)
        elif type_Y in ("continuous", None):
            # Mean squared error at the actual response values
            std = model.Y_std.numpy()
            predictions = predictions * std
            Y_test_p = Y_test_p * std
            pred_measure = np.sum(np.mean((predictions - Y_test_p) ** 2, axis=0)) # if multiple outputs, sum over all

        return pred_measure

    results = np.array(Parallel(n_jobs=njobs, verbose=2)(delayed(process)(i) for i in range(reps)))

    print("n={}, p={}, Y={}, X={}".format(n, p, Y_func.__name__, X_func.__name__))
    print("Mean {}: {:.4f}".format("Accuracy" if type_Y == "binary" else "MSE", results.mean(0)), "+/-", "SE: {:.4f}".format(results.std(0) / np.sqrt(reps)))
    with open("./results/simulation/{}/{}_{}_{}.pickle".format(foldername, n, Y_func.__name__, m), "wb") as f:
        pickle.dump(results, f)

    return results


def repeat_lc_lasso_reg(n, p, Y_func, X_func, Y_noise=0.1, lamseq=np.geomspace(0.001, 1, 30), njobs=-2, reps=100, verbose=False, seed=None):
    """
    LC-Lasso for continuous responses
    Uses the c-lasso library: https://github.com/Leo-Simpson/c-lasso/tree/master
    You can install it with `pip install c-lasso`.

    Input X should be zero-replaced count or compositional data
    """
    assert Y_func.__name__ in ["Y1", "Y2"], "Y_func must be either Y1 or Y2 for continuous responses."

    # Case-wise seed control
    if isinstance(seed, int):
        Y_idx = ("Y1", "Y2", "Y3", "Y4").index(Y_func.__name__) + 1
        targ = 2 if Y_func.__name__ in ["Y1", "Y3"] else 3
        seed = seed - (n * Y_idx * targ)

    ##############################################
    ###  Parameter fitting stage at the first run
    ##############################################

    print("Performing cross-validation on the first run to select the best lambda parameter...")

    RS = np.random.RandomState(seed)
    X = X_func(n, p, seed=RS)
    Y = Y_func(X, sigma=Y_noise, seed=RS)
    X = zero_replacement(X, method="min", val=0.5)  # Zero replacement

    # Cross validation for lambda selection
    scores = np.zeros((len(lamseq), 5))
    cv = _get_fold(folds=5, random_state=RS, type_Y="continuous")
    folds_indices = list(cv.split(X, Y))

    for i in range(len(lamseq)):
        for l, (train_idx, test_idx) in enumerate(folds_indices):
            X_train_cv, X_test_cv = X[train_idx], X[test_idx]
            Y_train_cv, Y_test_cv = Y[train_idx], Y[test_idx]

            model = _learn(X_train_cv, Y_train_cv, C=None, label=None, lam=lamseq[i])
            scores[i, l] = np.mean((_predict(model, X_test_cv) - Y_test_cv)**2)
    lamb_opt = lamseq[np.argmin(scores.mean(1))]
    if verbose:
        print("CV selected lambda: {:3f}".format(lamb_opt))

    print("CV done.\n")
    ##############################################

    def process(i, lamb_opt):
        """
        Function to process each repetition of the simulation.
        """
        RS = np.random.RandomState(seed + i)
        X = X_func(n=n, p=p, seed=RS)
        Y = Y_func(X, sigma=Y_noise, seed=RS)

        # Zero replacement
        X = zero_replacement(X, method="min", val=0.5)

        # Train the LC-Lasso model with the optimal lambda
        model = _learn(X, Y, C=None, label=None, lam=lamb_opt)

        # Independent test set
        X_test = X_func(n=n, p=p, seed=RS)
        Y_test = Y_func(X_test, sigma=Y_noise, seed=RS)
        X_test = zero_replacement(X_test, method="min", val=0.5)

        # Predictions
        predictions = _predict(model, X_test)

        # Mean squared error at the actual response values
        mse = np.mean((predictions - Y_test) ** 2)

        return mse

    results = np.array(Parallel(n_jobs=njobs, verbose=2)(delayed(process)(i, lamb_opt) for i in range(reps)))

    print("n={}, p={}, Y={}, X={}".format(n, p, Y_func.__name__, X_func.__name__))
    print("Mean MSE: {:.4f}".format(results.mean(0)), "+/-", "SE: {:.4f}".format(results.std(0) / np.sqrt(reps)))

    with open("./results/simulation/lc_lasso_results/{}_{}.pickle".format(n, Y_func.__name__), "wb") as f:
        pickle.dump(results, f)
    
    return results


def repeat_lc_lasso_clf(n, p, Y_func, X_func, Y_noise=0.1, lamseq=np.geomspace(0.001, 1, 30), njobs=-2, reps=100, verbose=False, seed=None):
    """
    Repeat training the log-contrast logistic lasso classifier for classification performance assessment.
    Y_func must be either Y3 or Y4, which are binary response variables.
    """
    import rpy2.robjects as ro
    from rpy2.robjects import numpy2ri
    # This may help ensure R environment is set up. Uncomment if needed.
    # setup_r_environment() 
    r = ro.r
    r.source("./reproducibility/other_methods/CoDA-Penalized-Regression/R/functions.R")
    r.source("./reproducibility/other_methods/CoDA-Penalized-Regression/R/functions_coda_penalized_regression.R")
    lamseq_r = ro.FloatVector(lamseq)
    
    assert Y_func.__name__ in ["Y3", "Y4"], "Y_func must be either Y3 or Y4 for binary classification."

    # Case-wise seed control
    if isinstance(seed, int):
        Y_idx = ("Y1", "Y2", "Y3", "Y4").index(Y_func.__name__) + 1
        targ = 2 if Y_func.__name__ in ["Y1", "Y3"] else 3
        seed = seed - (n * Y_idx * targ)

    ##############################################
    ###  Parameter fitting stage at the first run
    ##############################################

    print("Performing cross-validation on the first run to select the best lambda parameter...")

    RS = np.random.RandomState(seed)
    X = X_func(n, p, seed=RS)
    Y = Y_func(X, sigma=Y_noise, seed=RS)
    # Convert Y from {-1, 1} to {0, 1} for R compatibility
    Y = (Y + 1) / 2
    X = zero_replacement(X, method="min", val=0.5)  # Zero replacement
    
    # Manual cross-validation
    scores = np.zeros((len(lamseq), 5))
    cv = _get_fold(folds=5, random_state=RS, type_Y="binary")

    # Convert numpy arrays to R objects
    numpy2ri.activate()

    folds_indices = list(cv.split(X, Y))
    for i in range(len(lamseq)):
        for l, (train_idx, test_idx) in enumerate(folds_indices):
            X_train_cv, X_test_cv = X[train_idx], X[test_idx]
            Y_train_cv, Y_test_cv = Y[train_idx], Y[test_idx]

            # Convert to R object
            x_train_cv = ro.conversion.py2rpy(X_train_cv)
            x_test_cv = ro.conversion.py2rpy(X_test_cv)
            y_train_cv = ro.conversion.py2rpy(Y_train_cv)
            y_test_cv = ro.conversion.py2rpy(Y_test_cv)

            model = _safe_coda_logistic_lasso(r, ro.FactorVector([str(int(float(y))) for y in y_train_cv]), x_train_cv, lamseq_r[i])
            y_pred = r['predict_codalasso'](x_test_cv, model)
            # Convert matrix to vector if needed
            y_pred = r['as.vector'](y_pred)
            
            # R operations - R factors are 1-indexed, so we need to subtract 1
            y_test_numeric = r["-"](r["as.numeric"](ro.FactorVector([str(int(float(y))) for y in y_test_cv])), 1)
            scores[i, l] = r['mean'](r["=="](y_pred, y_test_numeric))[0]

    # Optimal lambda from CV
    lamb_idx = int(np.argmax(scores.mean(1)))
    lamb_opt = lamseq_r[lamb_idx]
    print("CV selected lambda: {:3f}".format(lamb_opt))
    print("CV done.\n")
    numpy2ri.deactivate()  # Deactivate numpy2ri to avoid conflicts with further numpy operations
    ##############################################

    def process(i, lamb_idx):
        """
        Function to process each repetition of the simulation.
        """
        import rpy2.robjects as ro
        from rpy2.robjects import numpy2ri
        # This may help ensure R environment is set up. Uncomment if needed.
        # setup_r_environment() 
        r = ro.r
        r.source("./reproducibility/other_methods/CoDA-Penalized-Regression/R/functions.R")
        r.source("./reproducibility/other_methods/CoDA-Penalized-Regression/R/functions_coda_penalized_regression.R")
        lamseq_r = ro.FloatVector(lamseq)
        lamb_opt = lamseq_r[lamb_idx] # optimal lambda from CV

        # Data generation
        RS = np.random.RandomState(seed + i)
        X = X_func(n=n, p=p, seed=RS)
        Y = Y_func(X, sigma=Y_noise, seed=RS)
        # Convert Y from {-1, 1} to {0, 1} for R compatibility
        Y = (Y + 1) / 2
        X = zero_replacement(X, method="min", val=0.5)  # Zero replacement
        X_test = X_func(n=n, p=p, seed=RS)  # Independent test set
        Y_test = Y_func(X_test, sigma=Y_noise, seed=RS)
        # Convert Y_test from {-1, 1} to {0, 1} for R compatibility
        Y_test = (Y_test + 1) / 2
        X_test = zero_replacement(X_test, method="min", val=0.5)  # Zero replacement

        numpy2ri.activate()
        # Convert to R object
        x = ro.conversion.py2rpy(X)
        y = ro.FactorVector([str(int(float(y))) for y in Y])
        x_test_r = ro.conversion.py2rpy(X_test)
        y_test_r = ro.FactorVector([str(int(float(y))) for y in Y_test])

        # Train the log-contrast logistic lasso classifier
        model = _safe_coda_logistic_lasso(r, y, x, lamb_opt)

        # Predictions
        y_pred = r['predict_codalasso'](x_test_r, model)
        # Convert matrix to vector if needed
        y_pred = r['as.vector'](y_pred)

        # Calculate accuracy - R factors are 1-indexed, so we need to subtract 1
        y_test_numeric = r["-"](r["as.numeric"](y_test_r), 1)
        accuracy = r['mean'](r["=="](y_pred, y_test_numeric))[0]

        return accuracy
    
    # Run the repetitions in parallel
    results = np.array(Parallel(n_jobs=njobs, verbose=2)(delayed(process)(i, lamb_idx) for i in range(reps)))   

    print("n={}, p={}, Y={}, X={}".format(n, p, Y_func.__name__, X_func.__name__))
    print("Mean accuracy: {:.4f}".format(results.mean(0)), "+/-", "SE: {:.4f}".format(results.std(0) / np.sqrt(reps)))
    with open("./results/simulation/lc_lasso_results/{}_{}.pickle".format(n, Y_func.__name__), "wb") as f:
        pickle.dump(results, f)
    
    return results

# KRR function
from sklearn.kernel_ridge import KernelRidge
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import GridSearchCV
from scipy.spatial.distance import pdist
def repeat_clr_kernel_krr(n, p, Y_func, X_func, Y_noise=0.1, reps=100, seed=None):

    assert Y_func.__name__ in ["Y1", "Y2"], "Y_func must be either Y1 or Y2 for continuous responses."

    # Case-wise seed control
    if isinstance(seed, int):
        Y_idx = ("Y1", "Y2", "Y3", "Y4").index(Y_func.__name__) + 1
        targ = 2 if Y_func.__name__ in ["Y1", "Y3"] else 3
        seed = seed - (n * Y_idx * targ)
    
    ###  Parameter fitting stage at the first run
    print("Performing cross-validation on the first run to select the best lambda parameter...")

    RS = np.random.RandomState(seed)
    X = X_func(n, p, seed=RS)
    Y = Y_func(X, sigma=Y_noise, seed=RS)
    
    # Zero replacement + clr
    X = zero_replacement(X, method="min", val=0.5)  
    X = clr(X)

    # Scale the train response (consistent with the CKDR method)
    Y_std = Y.std()
    Y = Y / Y_std  # Standardize the response variable
    
    # Cross-validation for parameter selection
    median_distance = np.median(pdist(X))
    sigma_list= np.array([i * median_distance for i in np.geomspace(1/2, 2., 5)])
    gamma_list = 1 / (2 * sigma_list ** 2)
    tuned_parameters = [{'kernel': ['rbf'], 'gamma': gamma_list,
                        'alpha': np.array([0.1, 1.])}]
    # Manual cross-validation
    cv = _get_fold(folds=5, random_state=RS, type_Y="continuous")
    reg = GridSearchCV(KernelRidge(), tuned_parameters, cv=cv, n_jobs=-1, scoring='neg_mean_squared_error')
    reg.fit(X, Y)

    alpha_opt = reg.best_params_['alpha']
    gamma_opt = reg.best_params_['gamma']

    print("CV done")

    mses = np.zeros(reps)
    for i in range(reps):
        RS = np.random.RandomState(seed + i)
        X = X_func(n=n, p=p, seed=RS)
        Y = Y_func(X, sigma=Y_noise, seed=RS)
        X_test = X_func(n=n, p=p, seed=RS)  # Independent test set
        Y_test = Y_func(X_test, sigma=Y_noise, seed=RS)

        # Zero replacement + clr
        X = clr(zero_replacement(X, method="min", val=0.5))
        X_test = clr(zero_replacement(X_test, method="min", val=0.5))

        # Scale the train response (consistent with the CKDR method)
        Y_std = Y.std()
        Y = Y / Y_std

        # Train the Kernel Ridge Regression model with the best parameters found in cross-validation
        model = KernelRidge(kernel='rbf', gamma=gamma_opt, alpha=alpha_opt)
        model.fit(X, Y)

        # Predictions + scale back
        predictions = model.predict(X_test) * Y_std

        # Mean squared error at the actual response values
        mses[i] = mean_squared_error(Y_test, predictions)

    print("Mean MSE:", np.mean(mses), "SE:", np.std(mses) / np.sqrt(reps))
    with open("./results/simulation/clr_kernel_results/{}_{}.pickle".format(n, Y_func.__name__), "wb") as f:
        pickle.dump(mses, f)
    return mses


from sklearn.svm import SVC
from sklearn.metrics import make_scorer, accuracy_score
def repeat_clr_kernel_svm(n, p, Y_func, X_func, Y_noise=0.1, kernel="rbf", C=1.0, njobs=-2, reps=100, verbose=False, seed=None):
    assert Y_func.__name__ in ["Y3", "Y4"], "Y_func must be either Y3 or Y4 for binary classification."

    # Case-wise seed control
    if isinstance(seed, int):
        Y_idx = ("Y1", "Y2", "Y3", "Y4").index(Y_func.__name__) + 1
        targ = 2 if Y_func.__name__ in ["Y1", "Y3"] else 3
        seed = seed - (n * Y_idx * targ)

    ### Parameter fitting stage at the first run
    print("Performing cross-validation on the first run to select the best parameters...")
    RS = np.random.RandomState(seed)
    X = X_func(n, p, seed=RS)
    Y = Y_func(X, sigma=Y_noise, seed=RS)

    # Zero replacement + clr
    X = clr(zero_replacement(X, method="min", val=0.5))

    # CV
    median_distance = np.median(pdist(X))
    sigma_list= np.array([i * median_distance for i in np.geomspace(1/2, 2., 5)])
    gamma_list = 1 / (2 * sigma_list ** 2)
    tuned_parameters = [{'kernel': ['rbf'], 'gamma': gamma_list,
                        'C': [1., 10.]}]

    # Manual cross-validation
    cv = _get_fold(folds=5, random_state=RS, type_Y="binary")
    clf = GridSearchCV(SVC(), tuned_parameters, cv=cv, n_jobs=-1, scoring=make_scorer(accuracy_score))
    clf.fit(X, Y)

    gamma_opt = clf.best_params_['gamma']
    C_opt = clf.best_params_['C']
    print("CV done")

    accuracies = np.zeros(reps)
    for i in range(reps):
        RS = np.random.RandomState(seed + i)
        X = X_func(n=n, p=p, seed=RS)
        Y = Y_func(X, sigma=Y_noise, seed=RS)
        X_test = X_func(n=n, p=p, seed=RS)
        Y_test = Y_func(X_test, sigma=Y_noise, seed=RS)

        # Zero replacement + clr
        X = clr(zero_replacement(X, method="min", val=0.5))
        X_test = clr(zero_replacement(X_test, method="min", val=0.5))

        # Train the SVM model with the best parameters found in cross-validation
        clf = SVC(kernel='rbf', gamma=gamma_opt, C=C_opt)
        clf.fit(X, Y)

        # Predictions
        predictions = clf.predict(X_test)

        accuracies[i] = accuracy_score(Y_test, predictions)

    print("Mean accuracy:", np.mean(accuracies), "SE:", np.std(accuracies)/np.sqrt(reps))
    with open("./results/simulation/clr_kernel_results/{}_{}.pickle".format(n, Y_func.__name__), "wb") as f:
        pickle.dump(accuracies, f)

    return accuracies


from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
def repeat_clr_rf_clf(n, p, Y_func, X_func, Y_noise=0.1, reps=100, njobs=-2, seed=None):
    assert Y_func.__name__ in ["Y3", "Y4"], "Y_func must be either Y3 or Y4 for binary classification."

    # Case-wise seed control
    if isinstance(seed, int):
        Y_idx = ("Y1", "Y2", "Y3", "Y4").index(Y_func.__name__) + 1
        targ = 2 if Y_func.__name__ in ["Y1", "Y3"] else 3
        seed = seed - (n * Y_idx * targ)

    def process(i):
        """
        Function to process each repetition of the simulation.
        """
        RS = np.random.RandomState(seed + i)
        X = X_func(n=n, p=p, seed=RS)
        Y = Y_func(X, sigma=Y_noise, seed=RS)

        # Zero replacement + clr
        X = clr(zero_replacement(X, method="min", val=0.5))

        # Independent test set
        X_test = X_func(n=n, p=p, seed=RS)
        Y_test = Y_func(X_test, sigma=Y_noise, seed=RS)

        # Zero replacement + clr for test set
        X_test = clr(zero_replacement(X_test, method="min", val=0.5))

        # Train the Random Forest model
        clf = RandomForestClassifier(n_estimators=100, random_state=RS)
        clf.fit(X, Y)

        # Predictions
        predictions = clf.predict(X_test)

        # Accuracy
        accuracy = accuracy_score(Y_test, predictions)

        return accuracy

    # Run the repetitions in parallel
    accuracies = np.array(Parallel(n_jobs=njobs, verbose=2)(delayed(process)(i) for i in range(reps)))

    print("Mean accuracy:", np.mean(accuracies), "SE:", np.std(accuracies)/np.sqrt(reps))
    with open("./results/simulation/clr_rf_results/{}_{}.pickle".format(n, Y_func.__name__), "wb") as f:
        pickle.dump(accuracies, f)

    return accuracies


def repeat_clr_rf_reg(n, p, Y_func, X_func, Y_noise=0.1, reps=100, njobs=-2, seed=None):
    assert Y_func.__name__ in ["Y1", "Y2"], "Y_func must be either Y1 or Y2 for continuous responses."

    # Case-wise seed control
    if isinstance(seed, int):
        Y_idx = ("Y1", "Y2", "Y3", "Y4").index(Y_func.__name__) + 1
        targ = 2 if Y_func.__name__ in ["Y1", "Y3"] else 3
        seed = seed - (n * Y_idx * targ)

    def process(i):
        """
        Function to process each repetition of the simulation.
        """
        RS = np.random.RandomState(seed + i)
        X = X_func(n=n, p=p, seed=RS)
        Y = Y_func(X, sigma=Y_noise, seed=RS)

        # Zero replacement + clr
        X = clr(zero_replacement(X, method="min", val=0.5))

        # Independent test set
        X_test = X_func(n=n, p=p, seed=RS)
        Y_test = Y_func(X_test, sigma=Y_noise, seed=RS)

        # Zero replacement + clr for test set
        X_test = clr(zero_replacement(X_test, method="min", val=0.5))

        # Train the Random Forest model
        reg = RandomForestRegressor(n_estimators=100, random_state=RS)
        reg.fit(X, Y)

        # Predictions
        predictions = reg.predict(X_test)

        # Mean squared error at the actual response values
        mse = mean_squared_error(Y_test, predictions)

        return mse
    
    # Run the repetitions in parallel
    mses = np.array(Parallel(n_jobs=njobs, verbose=2)(delayed(process)(i) for i in range(reps)))

    print("Mean squared error:", np.mean(mses), "SE:", np.std(mses)/np.sqrt(reps))
    with open("./results/simulation/clr_rf_results/{}_{}.pickle".format(n, Y_func.__name__), "wb") as f:
        pickle.dump(mses, f)
    return mses


#################################
### Zero replacement functions
#################################


def zero_replacement(X, method="count", val=0.5):
    """
    X: matrix of microbiome counts (or normalized counts)
    method: "count" - replace zero counts by val (default with val=0.5)
            "min" - replace zeros by x_min * val
            "sum" - Take X = X + val, uses numpy broadcasting
    
    returns zero-replaced covariates;
        not normalized (coda-lasso doens't require normalization)
    """
    if method == "count":
        Y = X.copy()
        Y[Y == 0] = val
        return Y
    elif method == "min":
        # row-wise Zero replacement; need normalization in this case
        Y = X.copy()
        for i in range(len(X)):
            Y[i] = np.where(Y[i] == 0, Y[i][Y[i] > 0].min() * val, Y[i])
        Y = Y / np.sum(Y, axis=1)[:, None]
        return Y
    elif method == "sum":
        return X + val


def clr(mat):
    """
    Performs centered log ratio transformation.
    Adapted from the `composition_stats` library.

    Parameters
    ----------
    mat : array_like, float
       a matrix of proportions where
       rows = compositions and
       columns = components
       each composition (row) must add up to unity

    Returns
    -------
    numpy.ndarray
         clr transformed matrix
    """
    lmat = np.log(mat)
    gm = lmat.mean(axis=-1, keepdims=True)
    return (lmat - gm).squeeze()


def _safe_coda_logistic_lasso(r, y_factor, x_matrix, lambda_val):
    """
    Helper function to safely call coda_logistic_lasso with proper column names.
    Parallel-safe by creating a properly named matrix directly in R.
    
    The R function coda_logistic_lasso expects X to have column names, otherwise
    it fails with: "Error in dimnames(x) <- dn : length of 'dimnames' [2] not equal to array extent"
    """
    # Create a data frame in R which automatically has proper column names
    # This is safer than assigning variables to global R environment
    r.assign('x_temp', x_matrix)
    r.assign('y_temp', y_factor)
    
    # Create the matrix with proper column names and call the function in one go
    # This minimizes the time variables exist in the R environment
    result = r('''
    {
        colnames(x_temp) <- paste0("Feature_", 1:ncol(x_temp))
        model_result <- coda_logistic_lasso(y_temp, x_temp, ''' + str(lambda_val) + ''')
        rm(x_temp, y_temp)  # Clean up immediately
        model_result
    }
    ''')
    
    return result


def _learn(Z, Y, C=None, label=None, lam="theoretical"):
    # Z: log-transformed compositional data
    # Default C: zero sum constraint

    ## LC-Lasso
    from classo import classo_problem

    problem = classo_problem(Z, Y, C, label=label)
    problem.formulation.concomitant = False
    problem.formulation.huber = False
    problem.formulation.intercept = True

    problem.model_selection.CV = False
    problem.model_selection.ALO = False
    problem.model_selection.StabSel = False

    problem.model_selection.LAMfixed = True
    problem.model_selection.LAMfixedparameters.lam = lam
    problem.solve()
    
    return problem


def _predict(model, X_new):
    beta = model.solution.LAMfixed.beta
    X_new = np.c_[np.ones(len(X_new)), X_new]
    return X_new @ beta