{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea90f132",
   "metadata": {},
   "source": [
    "## Simulation: subspace distance performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6832d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell ONLY ONCE to set up the path\n",
    "import os, sys\n",
    "os.chdir('..')\n",
    "# sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "# Import necessary training functions\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "MASTER_SEED = 20241225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d8167b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for simulation experiments\n",
    "from reproducibility.simulations import Y1, Y2, Y3, Y4, logistic_normal, repeat_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15354c8",
   "metadata": {},
   "source": [
    "## CKDR-$m^\\star$\n",
    "The **oracle** case in which the central compositional subspace dimension is well-specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf984f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24min with 100 jobs\n",
    "dists = []\n",
    "for n in [200, 500, 1000]:\n",
    "    for X_func in [logistic_normal]:\n",
    "        for Y_func in [Y1, Y2, Y3, Y4]:\n",
    "            dists.append(repeat_cv(n, 100, Y_func, X_func, njobs=100, reps=100, seed=MASTER_SEED, foldername=\"subsp_convergence\", load=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04a30031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subspace distances and ARI scores\n",
      "logistic_normal ==========\n",
      "  Y1\n",
      "    n=200\n",
      "\tMean distance: 0.1038 +/- SE: 0.0017\n",
      "\tMean ARI: 0.9954 +/- SE: 0.0016\n",
      "\tRank deficiency: 0\n",
      "    n=500\n",
      "\tMean distance: 0.0526 +/- SE: 0.0005\n",
      "\tMean ARI: 0.9942 +/- SE: 0.0058\n",
      "\tRank deficiency: 0\n",
      "    n=1000\n",
      "\tMean distance: 0.0339 +/- SE: 0.0003\n",
      "\tMean ARI: 0.9940 +/- SE: 0.0059\n",
      "\tRank deficiency: 0\n",
      "  Y2\n",
      "    n=200\n",
      "\tMean distance: 0.5592 +/- SE: 0.0049\n",
      "\tMean ARI: 0.6106 +/- SE: 0.0174\n",
      "\tRank deficiency: 0\n",
      "    n=500\n",
      "\tMean distance: 0.4402 +/- SE: 0.0064\n",
      "\tMean ARI: 0.8792 +/- SE: 0.0205\n",
      "\tRank deficiency: 0\n",
      "    n=1000\n",
      "\tMean distance: 0.3407 +/- SE: 0.0078\n",
      "\tMean ARI: 0.9433 +/- SE: 0.0148\n",
      "\tRank deficiency: 0\n",
      "  Y3\n",
      "    n=200\n",
      "\tMean distance: 0.3558 +/- SE: 0.0033\n",
      "\tMean ARI: 0.4551 +/- SE: 0.0066\n",
      "\tRank deficiency: 0\n",
      "    n=500\n",
      "\tMean distance: 0.1851 +/- SE: 0.0022\n",
      "\tMean ARI: 0.7396 +/- SE: 0.0090\n",
      "\tRank deficiency: 0\n",
      "    n=1000\n",
      "\tMean distance: 0.1202 +/- SE: 0.0011\n",
      "\tMean ARI: 0.9316 +/- SE: 0.0094\n",
      "\tRank deficiency: 0\n",
      "  Y4\n",
      "    n=200\n",
      "\tMean distance: 0.6435 +/- SE: 0.0022\n",
      "\tMean ARI: 0.4267 +/- SE: 0.0083\n",
      "\tRank deficiency: 0\n",
      "    n=500\n",
      "\tMean distance: 0.5702 +/- SE: 0.0028\n",
      "\tMean ARI: 0.6693 +/- SE: 0.0118\n",
      "\tRank deficiency: 0\n",
      "    n=1000\n",
      "\tMean distance: 0.5430 +/- SE: 0.0045\n",
      "\tMean ARI: 0.7104 +/- SE: 0.0156\n",
      "\tRank deficiency: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Subspace distances and ARI scores\")\n",
    "for X_func in [logistic_normal]:\n",
    "    print(X_func.__name__, \"=\"*10)\n",
    "    for Y_func in [Y1, Y2, Y3, Y4]:\n",
    "        print(\" \", Y_func.__name__)\n",
    "        for n in [200, 500, 1000]:\n",
    "            print(\"    n={}\".format(n))\n",
    "            with open(\"./results/simulation/subsp_convergence/op_{}_{}_{}{}.pickle\".format(n, Y_func.__name__, X_func.__name__, None), \"rb\") as f:\n",
    "                results = np.array(pickle.load(f))\n",
    "            print(\"\\tMean distance: {:.4f}\".format(results.mean(0)[0]), \"+/-\", \"SE: {:.4f}\".format(results.std(0)[0] / np.sqrt(100)))\n",
    "            print(\"\\tMean ARI: {:.4f}\".format(results.mean(0)[1]), \"+/-\", \"SE: {:.4f}\".format(results.std(0)[1] / np.sqrt(100)))\n",
    "            m = 2 if Y_func.__name__ in (\"Y1\", \"Y3\") else 3\n",
    "            print(\"\\tRank deficiency:\", np.sum(results[:, 2] < m))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb54b4c",
   "metadata": {},
   "source": [
    "## CKDR$^*$\n",
    "target dimension $m$ is cross-validated using the grid $\\{3, 4, 5, 6, 7\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896bdb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90min with 100 jobs\n",
    "dists = []\n",
    "for n in [200, 500, 1000]:\n",
    "    for X_func in [logistic_normal]:\n",
    "        for Y_func in [Y1, Y2, Y3, Y4]:  \n",
    "            # cv\n",
    "            m = \"cv\"\n",
    "            dists.append(repeat_cv(n, 100, Y_func, X_func, m=m, njobs=50, reps=100, seed=MASTER_SEED * 2, load=False, foldername=\"subsp_convergence\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e408fb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subspace distances and ARI scores\n",
      "logistic_normal ==========\n",
      "  Y1\n",
      "    n=200\n",
      "\tMean distance: 0.1032 +/- SE: 0.0043\n",
      "\tMean ARI: 0.8063 +/- SE: 0.0195\n",
      "\tRank deficiency: 0\n",
      "    n=500\n",
      "\tMean distance: 0.0522 +/- SE: 0.0005\n",
      "\tMean ARI: 0.9468 +/- SE: 0.0134\n",
      "\tRank deficiency: 0\n",
      "    n=1000\n",
      "\tMean distance: 0.0384 +/- SE: 0.0047\n",
      "\tMean ARI: 0.9807 +/- SE: 0.0077\n",
      "\tRank deficiency: 0\n",
      "  Y2\n",
      "    n=200\n",
      "\tMean distance: 0.5588 +/- SE: 0.0047\n",
      "\tMean ARI: 0.5412 +/- SE: 0.0158\n",
      "\tRank deficiency: 0\n",
      "    n=500\n",
      "\tMean distance: 0.4319 +/- SE: 0.0099\n",
      "\tMean ARI: 0.8403 +/- SE: 0.0215\n",
      "\tRank deficiency: 0\n",
      "    n=1000\n",
      "\tMean distance: 0.3172 +/- SE: 0.0066\n",
      "\tMean ARI: 0.8917 +/- SE: 0.0208\n",
      "\tRank deficiency: 0\n",
      "  Y3\n",
      "    n=200\n",
      "\tMean distance: 0.3279 +/- SE: 0.0052\n",
      "\tMean ARI: 0.4540 +/- SE: 0.0068\n",
      "\tRank deficiency: 0\n",
      "    n=500\n",
      "\tMean distance: 0.3388 +/- SE: 0.0178\n",
      "\tMean ARI: 0.5847 +/- SE: 0.0119\n",
      "\tRank deficiency: 0\n",
      "    n=1000\n",
      "\tMean distance: 0.1172 +/- SE: 0.0011\n",
      "\tMean ARI: 0.9006 +/- SE: 0.0126\n",
      "\tRank deficiency: 0\n",
      "  Y4\n",
      "    n=200\n",
      "\tMean distance: 0.6589 +/- SE: 0.0080\n",
      "\tMean ARI: 0.4709 +/- SE: 0.0070\n",
      "\tRank deficiency: 0\n",
      "    n=500\n",
      "\tMean distance: 0.6674 +/- SE: 0.0145\n",
      "\tMean ARI: 0.6236 +/- SE: 0.0109\n",
      "\tRank deficiency: 0\n",
      "    n=1000\n",
      "\tMean distance: 0.5564 +/- SE: 0.0067\n",
      "\tMean ARI: 0.7097 +/- SE: 0.0163\n",
      "\tRank deficiency: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Subspace distances and ARI scores\")\n",
    "for X_func in [logistic_normal]:\n",
    "    print(X_func.__name__, \"=\"*10)\n",
    "    for Y_func in [Y1, Y2, Y3, Y4]:\n",
    "        print(\" \", Y_func.__name__)\n",
    "        for n in [200, 500, 1000]:\n",
    "            print(\"    n={}\".format(n))\n",
    "            m = \"cv\"\n",
    "            with open(\"./results/simulation/subsp_convergence/op_{}_{}_{}{}.pickle\".format(n, Y_func.__name__, X_func.__name__, m), \"rb\") as f:\n",
    "                results = np.array(pickle.load(f))\n",
    "            print(\"\\tMean distance: {:.4f}\".format(results.mean(0)[0]), \"+/-\", \"SE: {:.4f}\".format(results.std(0)[0] / np.sqrt(100)))\n",
    "            print(\"\\tMean ARI: {:.4f}\".format(results.mean(0)[1]), \"+/-\", \"SE: {:.4f}\".format(results.std(0)[1] / np.sqrt(100)))\n",
    "            mstar = 2 if Y_func.__name__ in (\"Y1\", \"Y3\") else 3\n",
    "            print(\"\\tRank deficiency:\", np.sum(results[:, 2] < mstar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad380486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected target dimensions m:\n",
      "  Y1\n",
      "    n=200\n",
      "\t Selected m: 4\n",
      "\t True m^*: 2\n",
      "    n=500\n",
      "\t Selected m: 3\n",
      "\t True m^*: 2\n",
      "    n=1000\n",
      "\t Selected m: 3\n",
      "\t True m^*: 2\n",
      "  Y2\n",
      "    n=200\n",
      "\t Selected m: 4\n",
      "\t True m^*: 3\n",
      "    n=500\n",
      "\t Selected m: 7\n",
      "\t True m^*: 3\n",
      "    n=1000\n",
      "\t Selected m: 6\n",
      "\t True m^*: 3\n",
      "  Y3\n",
      "    n=200\n",
      "\t Selected m: 4\n",
      "\t True m^*: 2\n",
      "    n=500\n",
      "\t Selected m: 6\n",
      "\t True m^*: 2\n",
      "    n=1000\n",
      "\t Selected m: 3\n",
      "\t True m^*: 2\n",
      "  Y4\n",
      "    n=200\n",
      "\t Selected m: 7\n",
      "\t True m^*: 3\n",
      "    n=500\n",
      "\t Selected m: 6\n",
      "\t True m^*: 3\n",
      "    n=1000\n",
      "\t Selected m: 5\n",
      "\t True m^*: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Selected target dimensions m:\")\n",
    "for Y_func in [Y1, Y2, Y3, Y4]:\n",
    "    print(\" \", Y_func.__name__)\n",
    "    for n in [200, 500, 1000]:\n",
    "        print(\"    n={}\".format(n))\n",
    "        with open(\"./results/simulation/subsp_convergence/param_op_{}_{}_{}cv.pickle\".format(n, Y_func.__name__, logistic_normal.__name__), \"rb\") as f:\n",
    "            params = pickle.load(f)\n",
    "        epsilon, sigma, target_dim = params[\"epsilon\"], params[\"sigma_Z\"], params[\"target_dim\"]\n",
    "        print(\"\\t Selected m:\", target_dim)\n",
    "        print(\"\\t True m^*:\", 2 if Y_func.__name__ in (\"Y1\", \"Y3\") else 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa92f97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fd1999e",
   "metadata": {},
   "source": [
    "## RS-ES\n",
    "Check for continuous responses (Settings (I) and (II))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1d4475d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RS-ES results...\n",
      "Available conditions: [(200, 'Y1'), (200, 'Y2'), (500, 'Y1'), (500, 'Y2'), (1000, 'Y1'), (1000, 'Y2')]\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "# Load RS-ES results from MATLAB files\n",
    "rs_es_results = {}\n",
    "\n",
    "# Sample sizes and Y functions to load\n",
    "sample_sizes = [200, 500, 1000]\n",
    "Y_func_names = ['Y1', 'Y2']\n",
    "\n",
    "print(\"Loading RS-ES results...\")\n",
    "for n in sample_sizes:\n",
    "    for Y_func_name in Y_func_names:\n",
    "        filename = f'beta_rs_n{n}_{Y_func_name}.mat'\n",
    "        filepath = f'./results/simulation/rs_es_results/{filename}'\n",
    "        \n",
    "        if os.path.exists(filepath):\n",
    "            mat_data = loadmat(filepath)\n",
    "            rs_es_results[(n, Y_func_name)] = {\n",
    "                'beta_all': mat_data['beta_all']\n",
    "            }\n",
    "            # print(f\"  Loaded: {filename}\")\n",
    "        else:\n",
    "            print(f\"  Missing: {filename}\")\n",
    "\n",
    "print(\"Available conditions:\", list(rs_es_results.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0713b45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_cdr(beta_vec):\n",
    "    \"\"\"\n",
    "    Convert a beta vector to a compositional dimension reduction (CDR) matrix\n",
    "\n",
    "    beta_vec: 1D numpy array representing the beta coefficients of the linear relative-shift model\n",
    "    Returns: 2D numpy array (2 x d) representing the corresponding CDR matrix\n",
    "    \"\"\"\n",
    "    max_beta = np.max(beta_vec)\n",
    "    min_beta = np.min(beta_vec)\n",
    "    gap = max_beta - min_beta\n",
    "\n",
    "    P = np.zeros((2, len(beta_vec)))\n",
    "\n",
    "    for j in range(len(beta_vec)):\n",
    "        beta_j = beta_vec[j]\n",
    "        P[0, j] = (max_beta - beta_j) / gap\n",
    "        P[1, j] = (beta_j - min_beta) / gap\n",
    "    \n",
    "    # Return the CDR matrix P\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31dd1963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['beta_all'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73979fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RS-ES Results Summary\n",
      "==================================================\n",
      "\n",
      "Y1:\n",
      "  n=200:\n",
      "\tMean distance: 0.1280 +/- SE: 0.0012\n",
      "\tMean ARI: 0.9949 +/- SE: 0.0015\n",
      "  n=500:\n",
      "\tMean distance: 0.0646 +/- SE: 0.0005\n",
      "\tMean ARI: 0.9763 +/- SE: 0.0116\n",
      "  n=1000:\n",
      "\tMean distance: 0.0429 +/- SE: 0.0003\n",
      "\tMean ARI: 0.9882 +/- SE: 0.0083\n",
      "\n",
      "Y2:\n",
      "  n=200:\n",
      "\tMean distance: NA\n",
      "\tMean ARI: 0.5589 +/- SE: 0.0139\n",
      "  n=500:\n",
      "\tMean distance: NA\n",
      "\tMean ARI: 0.6826 +/- SE: 0.0212\n",
      "  n=1000:\n",
      "\tMean distance: NA\n",
      "\tMean ARI: 0.7461 +/- SE: 0.0233\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "from functions import KQuantiles\n",
    "from reproducibility.simulations import subsp_dist, get_true, true_mat\n",
    "\n",
    "# Analyze RS-ES results\n",
    "print(\"RS-ES Results Summary\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for Y_func_name in Y_func_names:\n",
    "    Y_func = Y1 if Y_func_name == 'Y1' else Y2\n",
    "    true_matrix = true_mat(100, Y_func)\n",
    "    true_cluster = get_true(100)\n",
    "    \n",
    "    print(f\"\\n{Y_func_name}:\")\n",
    "    for n in sample_sizes:\n",
    "        print(f\"  n={n}:\")\n",
    "        \n",
    "        data = rs_es_results[(n, Y_func_name)]\n",
    "        beta_all = data['beta_all']\n",
    "        reps = 100\n",
    "\n",
    "        # Extract beta coefficients from cell array, process them, and assess distances & ARIs\n",
    "        # Note: MATLAB cell arrays come as object arrays in Python\n",
    "        distances = []\n",
    "        aris = []\n",
    "        for i in range(reps):\n",
    "            beta_vec = np.array(beta_all[i, 0]).flatten()\n",
    "            P = convert_to_cdr(beta_vec)\n",
    "\n",
    "            # Calculate subspace distance\n",
    "            dist = subsp_dist(P, true_matrix)\n",
    "            distances.append(dist)\n",
    "\n",
    "            # Calculate ARI after clustering\n",
    "            RS = np.random.RandomState(MASTER_SEED + i)\n",
    "            clus = KQuantiles(n_clusters=3, random_state=RS, verbose=False)\n",
    "            clus.fit(P.T)\n",
    "            ari = adjusted_rand_score(true_cluster, clus.clusters)\n",
    "            aris.append(ari)\n",
    "        \n",
    "        # Store processed betas for potential further analysis\n",
    "        rs_es_results[(n, Y_func_name)]['subsp_distances'] = distances\n",
    "        rs_es_results[(n, Y_func_name)]['aris'] = aris\n",
    "\n",
    "        # Subspace distances to the true matrix\n",
    "        if Y_func_name == 'Y1':\n",
    "            print(\"\\tMean distance: {:.4f}\".format(np.mean(distances)), \"+/-\", \"SE: {:.4f}\".format(np.std(distances) / np.sqrt(reps)))\n",
    "        else:\n",
    "            print(\"\\tMean distance: NA\")\n",
    "        # Adjusted Rand Index (ARI) scores\n",
    "        print(\"\\tMean ARI: {:.4f}\".format(np.mean(aris)), \"+/-\", \"SE: {:.4f}\".format(np.std(aris) / np.sqrt(reps)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d65af9",
   "metadata": {},
   "source": [
    "The subspace distance computed for the response Y2 is not comparable to the other cases since the resulting matrix $P$ has smaller row space dimension than the central compositional subspace.  \n",
    "\n",
    "Technically speaking, this is because only the second principal angle (ignoring the trivial first principal angle induced by the vector $1_d$) is taken into account"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97308c02",
   "metadata": {},
   "source": [
    "## Amalgam\n",
    "Requires the R package `amalgam` and the `rpy2` environment   \n",
    "To favor the discrete method, we set the precise amalgamation $m = m^*$ case.  \n",
    "Since the package cannot deal with zero inputs, we replace zeros according to the same zero replacement rule as described in the paper (in each sample, zeros are replaced by the 50\\% of the minimum positive value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ae866a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reproducibility.simulations import repeat_amalgam\n",
    "\n",
    "n_list = [200, 500, 1000]\n",
    "Y_func_list = [Y3, Y4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f6d68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5 hours with 100 cores\n",
    "results_list = []\n",
    "for n in n_list:\n",
    "    for Y_func in Y_func_list:\n",
    "        print(f\"Running repeat_amalgam for n={n}, Y_func={Y_func.__name__}\")\n",
    "        result = repeat_amalgam(n, 100, Y_func, njobs=100, reps=100, seed=MASTER_SEED)\n",
    "        results_list.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f102d6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for n=200, Y_func=Y3:\n",
      "    n=200, p=100, Y=Y3\n",
      "\tMean distance: 0.5619 +/- SE: 0.0043\n",
      "\tMean ARI: 0.2018 +/- SE: 0.0048\n",
      "Results for n=500, Y_func=Y3:\n",
      "    n=500, p=100, Y=Y3\n",
      "\tMean distance: 0.4251 +/- SE: 0.0048\n",
      "\tMean ARI: 0.3420 +/- SE: 0.0059\n",
      "Results for n=1000, Y_func=Y3:\n",
      "    n=1000, p=100, Y=Y3\n",
      "\tMean distance: 0.3577 +/- SE: 0.0038\n",
      "\tMean ARI: 0.4059 +/- SE: 0.0044\n",
      "Results for n=200, Y_func=Y4:\n",
      "    n=200, p=100, Y=Y4\n",
      "\tMean distance: 0.7508 +/- SE: 0.0015\n",
      "\tMean ARI: 0.1742 +/- SE: 0.0053\n",
      "Results for n=500, Y_func=Y4:\n",
      "    n=500, p=100, Y=Y4\n",
      "\tMean distance: 0.7037 +/- SE: 0.0016\n",
      "\tMean ARI: 0.2527 +/- SE: 0.0060\n",
      "Results for n=1000, Y_func=Y4:\n",
      "    n=1000, p=100, Y=Y4\n",
      "\tMean distance: 0.6664 +/- SE: 0.0018\n",
      "\tMean ARI: 0.3450 +/- SE: 0.0089\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "from functions import KQuantiles\n",
    "from reproducibility.simulations import subsp_dist, get_true, true_mat\n",
    "\n",
    "p, reps = 100, 100\n",
    "\n",
    "\n",
    "for Y_func in Y_func_list:\n",
    "    for n in n_list:\n",
    "        print(f\"Results for n={n}, Y_func={Y_func.__name__}:\")\n",
    "        with open(\"./results/simulation/amalgam_results/op_{}_{}.pickle\".format(n, Y_func.__name__), \"rb\") as fi:\n",
    "            result_arrays = np.array(pickle.load(fi))\n",
    "        true_matrix = true_mat(100, Y_func)\n",
    "        true_cluster = get_true(100)\n",
    "\n",
    "        distances = []\n",
    "        aris = []\n",
    "        for i, W in enumerate(result_arrays):\n",
    "            # Calculate subspace distance\n",
    "            dist = subsp_dist(W, true_matrix)\n",
    "            distances.append(dist)\n",
    "\n",
    "            # Calculate ARI after clustering\n",
    "            RS = np.random.RandomState(MASTER_SEED + i)\n",
    "            n_clusters = 3\n",
    "            # Use KQuantiles for clustering\n",
    "            clus = KQuantiles(n_clusters=n_clusters, random_state=RS, verbose=False)\n",
    "            clus.fit(W.T)\n",
    "            ari = adjusted_rand_score(true_cluster, clus.clusters)\n",
    "            aris.append(ari)\n",
    "\n",
    "        print(\"    n={}, p={}, Y={}\".format(n, p, Y_func.__name__))\n",
    "        print(\"\\tMean distance: {:.4f}\".format(np.mean(distances)), \"+/-\", \"SE: {:.4f}\".format(np.std(distances) / np.sqrt(reps)))\n",
    "        print(\"\\tMean ARI: {:.4f}\".format(np.mean(aris)), \"+/-\", \"SE: {:.4f}\".format(np.std(aris) / np.sqrt(reps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d191dfac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96ec369c",
   "metadata": {},
   "source": [
    "## Export table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1b39afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results collected successfully!\n"
     ]
    }
   ],
   "source": [
    "# Self-contained table generation with all necessary imports and functions\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.io import loadmat\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "# Set master seed\n",
    "MASTER_SEED = 20241225\n",
    "\n",
    "# Import simulation functions\n",
    "from reproducibility.simulations import Y1, Y2, Y3, Y4, subsp_dist, get_true, true_mat\n",
    "from functions import KQuantiles\n",
    "\n",
    "# Load RS-ES results\n",
    "def load_rs_es_results():\n",
    "    rs_es_results = {}\n",
    "    sample_sizes = [200, 500, 1000]\n",
    "    Y_func_names = ['Y1', 'Y2']\n",
    "    \n",
    "    for n in sample_sizes:\n",
    "        for Y_func_name in Y_func_names:\n",
    "            filename = f'beta_rs_n{n}_{Y_func_name}.mat'\n",
    "            filepath = f'./results/simulation/rs_es_results/{filename}'\n",
    "            \n",
    "            if os.path.exists(filepath):\n",
    "                mat_data = loadmat(filepath)\n",
    "                rs_es_results[(n, Y_func_name)] = {\n",
    "                    'beta_all': mat_data['beta_all'],\n",
    "                    'reps': mat_data['beta_all'].shape[0]\n",
    "                }\n",
    "                \n",
    "                # Process RS-ES results\n",
    "                Y_func = Y1 if Y_func_name == 'Y1' else Y2\n",
    "                true_matrix = true_mat(100, Y_func)\n",
    "                true_cluster = get_true(100)\n",
    "                \n",
    "                beta_all = mat_data['beta_all']\n",
    "                reps = beta_all.shape[0]\n",
    "                \n",
    "                distances = []\n",
    "                aris = []\n",
    "                for i in range(reps):\n",
    "                    beta_vec = np.array(beta_all[i, 0]).flatten()\n",
    "                    \n",
    "                    # Convert to CDR matrix\n",
    "                    max_beta = np.max(beta_vec)\n",
    "                    min_beta = np.min(beta_vec)\n",
    "                    gap = max_beta - min_beta\n",
    "                    P = np.zeros((2, len(beta_vec)))\n",
    "                    for j in range(len(beta_vec)):\n",
    "                        beta_j = beta_vec[j]\n",
    "                        P[0, j] = (max_beta - beta_j) / gap\n",
    "                        P[1, j] = (beta_j - min_beta) / gap\n",
    "                    \n",
    "                    # Calculate subspace distance\n",
    "                    dist = subsp_dist(P, true_matrix)\n",
    "                    distances.append(dist)\n",
    "                    \n",
    "                    # Calculate ARI after clustering\n",
    "                    RS = np.random.RandomState(MASTER_SEED + i)\n",
    "                    clus = KQuantiles(n_clusters=3, random_state=RS, verbose=False)\n",
    "                    clus.fit(P.T)\n",
    "                    ari = adjusted_rand_score(true_cluster, clus.clusters)\n",
    "                    aris.append(ari)\n",
    "                \n",
    "                rs_es_results[(n, Y_func_name)]['subsp_distances'] = distances\n",
    "                rs_es_results[(n, Y_func_name)]['aris'] = aris\n",
    "    \n",
    "    return rs_es_results\n",
    "\n",
    "# Load RS-ES results\n",
    "rs_es_results = load_rs_es_results()\n",
    "\n",
    "# Collect all results for the table\n",
    "def collect_results():\n",
    "    results = {}\n",
    "    \n",
    "    # CKDR-m* (Oracle)\n",
    "    for Y_func in [Y1, Y2, Y3, Y4]:\n",
    "        for n in [200, 500, 1000]:\n",
    "            with open(\"./results/simulation/subsp_convergence/op_{}_{}_{}{}.pickle\".format(n, Y_func.__name__, \"logistic_normal\", None), \"rb\") as f:\n",
    "                res = np.array(pickle.load(f))\n",
    "            mean_dist = res.mean(0)[0] * 100  # multiply by 100\n",
    "            se_dist = res.std(0)[0] / np.sqrt(100) * 100\n",
    "            mean_ari = res.mean(0)[1] * 100\n",
    "            se_ari = res.std(0)[1] / np.sqrt(100) * 100\n",
    "            \n",
    "            results[('CKDR-$m^*$', n, Y_func.__name__)] = {\n",
    "                'dist_mean': mean_dist, 'dist_se': se_dist,\n",
    "                'ari_mean': mean_ari, 'ari_se': se_ari\n",
    "            }\n",
    "    \n",
    "    # CKDR (Cross-validated)\n",
    "    for Y_func in [Y1, Y2, Y3, Y4]:\n",
    "        for n in [200, 500, 1000]:\n",
    "            with open(\"./results/simulation/subsp_convergence/op_{}_{}_{}{}.pickle\".format(n, Y_func.__name__, \"logistic_normal\", \"cv\"), \"rb\") as f:\n",
    "                res = np.array(pickle.load(f))\n",
    "            mean_dist = res.mean(0)[0] * 100\n",
    "            se_dist = res.std(0)[0] / np.sqrt(100) * 100\n",
    "            mean_ari = res.mean(0)[1] * 100\n",
    "            se_ari = res.std(0)[1] / np.sqrt(100) * 100\n",
    "            \n",
    "            results[('CKDR', n, Y_func.__name__)] = {\n",
    "                'dist_mean': mean_dist, 'dist_se': se_dist,\n",
    "                'ari_mean': mean_ari, 'ari_se': se_ari\n",
    "            }\n",
    "    \n",
    "    # RS-ES (subspace distance only for Y1, ARI for both Y1 and Y2)\n",
    "    for Y_func_name in ['Y1', 'Y2']:\n",
    "        for n in [200, 500, 1000]:\n",
    "            if (n, Y_func_name) in rs_es_results:\n",
    "                aris = rs_es_results[(n, Y_func_name)]['aris']\n",
    "                mean_ari = np.mean(aris) * 100\n",
    "                se_ari = np.std(aris) / np.sqrt(len(aris)) * 100\n",
    "                \n",
    "                # For subspace distance: only use Y1 results\n",
    "                if Y_func_name == 'Y1':\n",
    "                    distances = rs_es_results[(n, Y_func_name)]['subsp_distances']\n",
    "                    mean_dist = np.mean(distances) * 100\n",
    "                    se_dist = np.std(distances) / np.sqrt(len(distances)) * 100\n",
    "                else:  # Y2\n",
    "                    mean_dist = '--'\n",
    "                    se_dist = '--'\n",
    "                \n",
    "                results[('RS-ES', n, Y_func_name)] = {\n",
    "                    'dist_mean': mean_dist, 'dist_se': se_dist,\n",
    "                    'ari_mean': mean_ari, 'ari_se': se_ari\n",
    "                }\n",
    "            else:\n",
    "                # Fill with -- for missing results\n",
    "                results[('RS-ES', n, Y_func_name)] = {\n",
    "                    'dist_mean': '--', 'dist_se': '--',\n",
    "                    'ari_mean': '--', 'ari_se': '--'\n",
    "                }\n",
    "    \n",
    "    # For Y3 and Y4, RS-ES is not applicable\n",
    "    for Y_func_name in ['Y3', 'Y4']:\n",
    "        for n in [200, 500, 1000]:\n",
    "            results[('RS-ES', n, Y_func_name)] = {\n",
    "                'dist_mean': '--', 'dist_se': '--',\n",
    "                'ari_mean': '--', 'ari_se': '--'\n",
    "            }\n",
    "    \n",
    "    # Amalgam (only Y3 and Y4)\n",
    "    for Y_func in [Y3, Y4]:\n",
    "        for n in [200, 500, 1000]:\n",
    "            try:\n",
    "                with open(\"./results/simulation/amalgam_results/op_{}_{}.pickle\".format(n, Y_func.__name__), \"rb\") as fi:\n",
    "                    result_arrays = np.array(pickle.load(fi))\n",
    "                true_matrix = true_mat(100, Y_func)\n",
    "                true_cluster = get_true(100)\n",
    "\n",
    "                distances = []\n",
    "                aris = []\n",
    "                for i, W in enumerate(result_arrays):\n",
    "                    # Calculate subspace distance\n",
    "                    dist = subsp_dist(W, true_matrix)\n",
    "                    distances.append(dist)\n",
    "\n",
    "                    # Calculate ARI after clustering\n",
    "                    RS = np.random.RandomState(MASTER_SEED + i)\n",
    "                    n_clusters = 3\n",
    "                    clus = KQuantiles(n_clusters=n_clusters, random_state=RS, verbose=False)\n",
    "                    clus.fit(W.T)\n",
    "                    ari = adjusted_rand_score(true_cluster, clus.clusters)\n",
    "                    aris.append(ari)\n",
    "                \n",
    "                mean_dist = np.mean(distances) * 100\n",
    "                se_dist = np.std(distances) / np.sqrt(len(distances)) * 100\n",
    "                mean_ari = np.mean(aris) * 100\n",
    "                se_ari = np.std(aris) / np.sqrt(len(aris)) * 100\n",
    "                \n",
    "                results[('Amalgam', n, Y_func.__name__)] = {\n",
    "                    'dist_mean': mean_dist, 'dist_se': se_dist,\n",
    "                    'ari_mean': mean_ari, 'ari_se': se_ari\n",
    "                }\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading Amalgam results for {Y_func.__name__}, n={n}: {e}\")\n",
    "                results[('Amalgam', n, Y_func.__name__)] = {\n",
    "                    'dist_mean': '--', 'dist_se': '--',\n",
    "                    'ari_mean': '--', 'ari_se': '--'\n",
    "                }\n",
    "    \n",
    "    # For Y1 and Y2, Amalgam is not applicable\n",
    "    for Y_func_name in ['Y1', 'Y2']:\n",
    "        for n in [200, 500, 1000]:\n",
    "            results[('Amalgam', n, Y_func_name)] = {\n",
    "                'dist_mean': '--', 'dist_se': '--',\n",
    "                'ari_mean': '--', 'ari_se': '--'\n",
    "            }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Collect results\n",
    "all_results = collect_results()\n",
    "\n",
    "print(\"Results collected successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4619a51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('CKDR-$m^*$', 200, 'Y1'): {'dist_mean': 10.377841592809256,\n",
       "  'dist_se': 0.1711307198065112,\n",
       "  'ari_mean': 99.5435175653203,\n",
       "  'ari_se': 0.15511198125069928},\n",
       " ('CKDR-$m^*$', 500, 'Y1'): {'dist_mean': 5.262336106620131,\n",
       "  'dist_se': 0.05393145015046639,\n",
       "  'ari_mean': 99.41981844802342,\n",
       "  'ari_se': 0.5772733554577129},\n",
       " ('CKDR-$m^*$', 1000, 'Y1'): {'dist_mean': 3.394943860435841,\n",
       "  'dist_se': 0.03458452402674914,\n",
       "  'ari_mean': 99.40349414787325,\n",
       "  'ari_se': 0.5935158290266943},\n",
       " ('CKDR-$m^*$', 200, 'Y2'): {'dist_mean': 55.92333593521543,\n",
       "  'dist_se': 0.49315113881599054,\n",
       "  'ari_mean': 61.057394483063874,\n",
       "  'ari_se': 1.7372540442829827},\n",
       " ('CKDR-$m^*$', 500, 'Y2'): {'dist_mean': 44.01609017604641,\n",
       "  'dist_se': 0.6424024838752485,\n",
       "  'ari_mean': 87.92453851921508,\n",
       "  'ari_se': 2.050654083522289},\n",
       " ('CKDR-$m^*$', 1000, 'Y2'): {'dist_mean': 34.065999068683915,\n",
       "  'dist_se': 0.7755821802377287,\n",
       "  'ari_mean': 94.32776296528078,\n",
       "  'ari_se': 1.4808127915154656},\n",
       " ('CKDR-$m^*$', 200, 'Y3'): {'dist_mean': 35.57851921638309,\n",
       "  'dist_se': 0.33402495641625995,\n",
       "  'ari_mean': 45.512017391954835,\n",
       "  'ari_se': 0.6614046733526153},\n",
       " ('CKDR-$m^*$', 500, 'Y3'): {'dist_mean': 18.514745435028512,\n",
       "  'dist_se': 0.21908991586726828,\n",
       "  'ari_mean': 73.95715686378199,\n",
       "  'ari_se': 0.9002812136305123},\n",
       " ('CKDR-$m^*$', 1000, 'Y3'): {'dist_mean': 12.017454301959017,\n",
       "  'dist_se': 0.11216748291463749,\n",
       "  'ari_mean': 93.15974789022428,\n",
       "  'ari_se': 0.9364099376287137},\n",
       " ('CKDR-$m^*$', 200, 'Y4'): {'dist_mean': 64.34761608464957,\n",
       "  'dist_se': 0.21640266169744476,\n",
       "  'ari_mean': 42.67252182690053,\n",
       "  'ari_se': 0.8266681983412846},\n",
       " ('CKDR-$m^*$', 500, 'Y4'): {'dist_mean': 57.023945482462565,\n",
       "  'dist_se': 0.28197387348624814,\n",
       "  'ari_mean': 66.93486808292471,\n",
       "  'ari_se': 1.1775803273612742},\n",
       " ('CKDR-$m^*$', 1000, 'Y4'): {'dist_mean': 54.2982555109708,\n",
       "  'dist_se': 0.4547584465442485,\n",
       "  'ari_mean': 71.03912907873658,\n",
       "  'ari_se': 1.557877230040899},\n",
       " ('CKDR', 200, 'Y1'): {'dist_mean': 10.323309429188754,\n",
       "  'dist_se': 0.43169945300272444,\n",
       "  'ari_mean': 80.63129411161006,\n",
       "  'ari_se': 1.9495670067365696},\n",
       " ('CKDR', 500, 'Y1'): {'dist_mean': 5.217741183732735,\n",
       "  'dist_se': 0.048543713768209235,\n",
       "  'ari_mean': 94.68359914089058,\n",
       "  'ari_se': 1.3373330574594338},\n",
       " ('CKDR', 1000, 'Y1'): {'dist_mean': 3.840831694646829,\n",
       "  'dist_se': 0.46647718733053645,\n",
       "  'ari_mean': 98.0662056350327,\n",
       "  'ari_se': 0.7692715060584644},\n",
       " ('CKDR', 200, 'Y2'): {'dist_mean': 55.87783472463289,\n",
       "  'dist_se': 0.4712808300075342,\n",
       "  'ari_mean': 54.12296089350674,\n",
       "  'ari_se': 1.5780742093027065},\n",
       " ('CKDR', 500, 'Y2'): {'dist_mean': 43.194330690928076,\n",
       "  'dist_se': 0.9916796946399058,\n",
       "  'ari_mean': 84.03456533175275,\n",
       "  'ari_se': 2.146519350660193},\n",
       " ('CKDR', 1000, 'Y2'): {'dist_mean': 31.721092191354234,\n",
       "  'dist_se': 0.6583411796164383,\n",
       "  'ari_mean': 89.17193201722466,\n",
       "  'ari_se': 2.082994469497541},\n",
       " ('CKDR', 200, 'Y3'): {'dist_mean': 32.78798197174697,\n",
       "  'dist_se': 0.5229645285804503,\n",
       "  'ari_mean': 45.3985602784252,\n",
       "  'ari_se': 0.6794293326131599},\n",
       " ('CKDR', 500, 'Y3'): {'dist_mean': 33.884929723172725,\n",
       "  'dist_se': 1.7841537535887557,\n",
       "  'ari_mean': 58.47038515745302,\n",
       "  'ari_se': 1.1935785820900209},\n",
       " ('CKDR', 1000, 'Y3'): {'dist_mean': 11.723284658272574,\n",
       "  'dist_se': 0.11155998719530648,\n",
       "  'ari_mean': 90.0610302258873,\n",
       "  'ari_se': 1.2581952478042024},\n",
       " ('CKDR', 200, 'Y4'): {'dist_mean': 65.893738277898,\n",
       "  'dist_se': 0.8004932481102327,\n",
       "  'ari_mean': 47.08984699854824,\n",
       "  'ari_se': 0.7035297756766627},\n",
       " ('CKDR', 500, 'Y4'): {'dist_mean': 66.7358732489539,\n",
       "  'dist_se': 1.4460630833059571,\n",
       "  'ari_mean': 62.35748191337358,\n",
       "  'ari_se': 1.0854386657138972},\n",
       " ('CKDR', 1000, 'Y4'): {'dist_mean': 55.63580082068928,\n",
       "  'dist_se': 0.667967738460429,\n",
       "  'ari_mean': 70.97063402415594,\n",
       "  'ari_se': 1.633566659061596},\n",
       " ('RS-ES', 200, 'Y1'): {'dist_mean': 12.797947591462277,\n",
       "  'dist_se': 0.11711141639056377,\n",
       "  'ari_mean': 99.49076599546048,\n",
       "  'ari_se': 0.14672992834963727},\n",
       " ('RS-ES', 500, 'Y1'): {'dist_mean': 6.460479834928587,\n",
       "  'dist_se': 0.05379423041429536,\n",
       "  'ari_mean': 97.62794847754753,\n",
       "  'ari_se': 1.1621565244309082},\n",
       " ('RS-ES', 1000, 'Y1'): {'dist_mean': 4.2927173215786425,\n",
       "  'dist_se': 0.034192485747371784,\n",
       "  'ari_mean': 98.81558912386707,\n",
       "  'ari_se': 0.8290876132930513},\n",
       " ('RS-ES', 200, 'Y2'): {'dist_mean': '--',\n",
       "  'dist_se': '--',\n",
       "  'ari_mean': 55.890207213289514,\n",
       "  'ari_se': 1.3884423342525858},\n",
       " ('RS-ES', 500, 'Y2'): {'dist_mean': '--',\n",
       "  'dist_se': '--',\n",
       "  'ari_mean': 68.25899161202332,\n",
       "  'ari_se': 2.1169935228067627},\n",
       " ('RS-ES', 1000, 'Y2'): {'dist_mean': '--',\n",
       "  'dist_se': '--',\n",
       "  'ari_mean': 74.6087202251144,\n",
       "  'ari_se': 2.3321240282006874},\n",
       " ('RS-ES', 200, 'Y3'): {'dist_mean': '--',\n",
       "  'dist_se': '--',\n",
       "  'ari_mean': '--',\n",
       "  'ari_se': '--'},\n",
       " ('RS-ES', 500, 'Y3'): {'dist_mean': '--',\n",
       "  'dist_se': '--',\n",
       "  'ari_mean': '--',\n",
       "  'ari_se': '--'},\n",
       " ('RS-ES', 1000, 'Y3'): {'dist_mean': '--',\n",
       "  'dist_se': '--',\n",
       "  'ari_mean': '--',\n",
       "  'ari_se': '--'},\n",
       " ('RS-ES', 200, 'Y4'): {'dist_mean': '--',\n",
       "  'dist_se': '--',\n",
       "  'ari_mean': '--',\n",
       "  'ari_se': '--'},\n",
       " ('RS-ES', 500, 'Y4'): {'dist_mean': '--',\n",
       "  'dist_se': '--',\n",
       "  'ari_mean': '--',\n",
       "  'ari_se': '--'},\n",
       " ('RS-ES', 1000, 'Y4'): {'dist_mean': '--',\n",
       "  'dist_se': '--',\n",
       "  'ari_mean': '--',\n",
       "  'ari_se': '--'},\n",
       " ('Amalgam', 200, 'Y3'): {'dist_mean': 56.191478362195355,\n",
       "  'dist_se': 0.4267855918723766,\n",
       "  'ari_mean': 20.175453211549474,\n",
       "  'ari_se': 0.4846607798807417},\n",
       " ('Amalgam', 500, 'Y3'): {'dist_mean': 42.50651616527022,\n",
       "  'dist_se': 0.4813260340704067,\n",
       "  'ari_mean': 34.20181749178058,\n",
       "  'ari_se': 0.5933164733172249},\n",
       " ('Amalgam', 1000, 'Y3'): {'dist_mean': 35.766065368593466,\n",
       "  'dist_se': 0.38074129879372653,\n",
       "  'ari_mean': 40.592359003063564,\n",
       "  'ari_se': 0.4393128587334605},\n",
       " ('Amalgam', 200, 'Y4'): {'dist_mean': 75.08397399231433,\n",
       "  'dist_se': 0.15410391290018866,\n",
       "  'ari_mean': 17.419930334862833,\n",
       "  'ari_se': 0.5267541714604567},\n",
       " ('Amalgam', 500, 'Y4'): {'dist_mean': 70.36850820671762,\n",
       "  'dist_se': 0.15584934884915316,\n",
       "  'ari_mean': 25.269911842497354,\n",
       "  'ari_se': 0.5994045274487897},\n",
       " ('Amalgam', 1000, 'Y4'): {'dist_mean': 66.642861897268,\n",
       "  'dist_se': 0.18020025236289977,\n",
       "  'ari_mean': 34.49686702303309,\n",
       "  'ari_se': 0.8871963103814378},\n",
       " ('Amalgam', 200, 'Y1'): {'dist_mean': '--',\n",
       "  'dist_se': '--',\n",
       "  'ari_mean': '--',\n",
       "  'ari_se': '--'},\n",
       " ('Amalgam', 500, 'Y1'): {'dist_mean': '--',\n",
       "  'dist_se': '--',\n",
       "  'ari_mean': '--',\n",
       "  'ari_se': '--'},\n",
       " ('Amalgam', 1000, 'Y1'): {'dist_mean': '--',\n",
       "  'dist_se': '--',\n",
       "  'ari_mean': '--',\n",
       "  'ari_se': '--'},\n",
       " ('Amalgam', 200, 'Y2'): {'dist_mean': '--',\n",
       "  'dist_se': '--',\n",
       "  'ari_mean': '--',\n",
       "  'ari_se': '--'},\n",
       " ('Amalgam', 500, 'Y2'): {'dist_mean': '--',\n",
       "  'dist_se': '--',\n",
       "  'ari_mean': '--',\n",
       "  'ari_se': '--'},\n",
       " ('Amalgam', 1000, 'Y2'): {'dist_mean': '--',\n",
       "  'dist_se': '--',\n",
       "  'ari_mean': '--',\n",
       "  'ari_se': '--'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76ed12f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL CUSTOM TABLE DESIGN\n",
      "================================================================================\n",
      "FINAL CUSTOM TABLE:\n",
      "--------------------------------------------------\n",
      "\\begin{table}[htbp]\n",
      "\\centering\n",
      "\\caption{Simulation Results: Subspace Distance and ARI}\n",
      "\\label{tab:simulation_final}\n",
      "\\begin{tabular}{llccccccc}\n",
      "\\toprule\n",
      "Setting & Method & \\multicolumn{3}{c}{Subspace Distance $\\times 100$} & \\multicolumn{3}{c}{ARI $\\times 100$} \\\\\n",
      "\\cmidrule(lr){3-5} \\cmidrule(lr){6-8}\n",
      "& & $n=200$ & $n=500$ & $n=1000$ & $n=200$ & $n=500$ & $n=1000$ \\\\\n",
      "\\midrule\n",
      "\\multirow{3}{*}{(I)} & CKDR-$m^*$ & 10.4 (0.2) & 5.3 (0.1) & \\textbf{3.4 (0.0)} & \\textbf{99.5 (0.2)} & \\textbf{99.4 (0.6)} & \\textbf{99.4 (0.6)} \\\\\n",
      " & CKDR & \\textbf{10.3 (0.4)} & \\textbf{5.2 (0.0)} & 3.8 (0.5) & 80.6 (1.9) & 94.7 (1.3) & 98.1 (0.8) \\\\\n",
      " & RS-ES & 12.8 (0.1) & 6.5 (0.1) & 4.3 (0.0) & 99.5 (0.1) & 97.6 (1.2) & 98.8 (0.8) \\\\\n",
      "\\midrule\n",
      "\\multirow{3}{*}{(II)} & CKDR-$m^*$ & 55.9 (0.5) & 44.0 (0.6) & 34.1 (0.8) & \\textbf{61.1 (1.7)} & \\textbf{87.9 (2.1)} & \\textbf{94.3 (1.5)} \\\\\n",
      " & CKDR & \\textbf{55.9 (0.5)} & \\textbf{43.2 (1.0)} & \\textbf{31.7 (0.7)} & 54.1 (1.6) & 84.0 (2.1) & 89.2 (2.1) \\\\\n",
      " & RS-ES & -- & -- & -- & 55.9 (1.4) & 68.3 (2.1) & 74.6 (2.3) \\\\\n",
      "\\midrule\n",
      "\\multirow{3}{*}{(III)} & CKDR-$m^*$ & 35.6 (0.3) & \\textbf{18.5 (0.2)} & 12.0 (0.1) & \\textbf{45.5 (0.7)} & \\textbf{74.0 (0.9)} & \\textbf{93.2 (0.9)} \\\\\n",
      " & CKDR & \\textbf{32.8 (0.5)} & 33.9 (1.8) & \\textbf{11.7 (0.1)} & 45.4 (0.7) & 58.5 (1.2) & 90.1 (1.3) \\\\\n",
      " & Amalgam & 56.2 (0.4) & 42.5 (0.5) & 35.8 (0.4) & 20.2 (0.5) & 34.2 (0.6) & 40.6 (0.4) \\\\\n",
      "\\midrule\n",
      "\\multirow{3}{*}{(IV)} & CKDR-$m^*$ & \\textbf{64.3 (0.2)} & \\textbf{57.0 (0.3)} & \\textbf{54.3 (0.5)} & 42.7 (0.8) & \\textbf{66.9 (1.2)} & \\textbf{71.0 (1.6)} \\\\\n",
      " & CKDR & 65.9 (0.8) & 66.7 (1.4) & 55.6 (0.7) & \\textbf{47.1 (0.7)} & 62.4 (1.1) & 71.0 (1.6) \\\\\n",
      " & Amalgam & 75.1 (0.2) & 70.4 (0.2) & 66.6 (0.2) & 17.4 (0.5) & 25.3 (0.6) & 34.5 (0.9) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\\n\\nFinal custom table saved to 'simulation_final_table.tex'!\n",
      "\\nThis design shows:\n",
      "- CKDR methods: All 4 settings (I-IV) with multirow\n",
      "- RS-ES: Only settings (I-II) for continuous responses\n",
      "- Amalgam: Only settings (III-IV) for discrete responses\n",
      "- Optimal values are boldfaced within each setting\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL CUSTOM TABLE DESIGN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def format_result(mean, se, is_best=False):\n",
    "    \"\"\"Format mean (se) for LaTeX table\"\"\"\n",
    "    if mean == '--':\n",
    "        return '--'\n",
    "    formatted = f\"{mean:.1f} ({se:.1f})\"\n",
    "    if is_best:\n",
    "        formatted = f\"\\\\textbf{{{formatted}}}\"\n",
    "    return formatted\n",
    "\n",
    "def generate_final_custom_table():\n",
    "    \"\"\"Generate the final custom table design with switched columns\"\"\"\n",
    "    \n",
    "    sample_sizes = [200, 500, 1000]\n",
    "    y_settings = ['Y1', 'Y2', 'Y3', 'Y4']\n",
    "    y_labels = ['(I)', '(II)', '(III)', '(IV)']\n",
    "    \n",
    "    # Find best values for each setting across sample sizes\n",
    "    def find_best_values_final():\n",
    "        best_dist = {}  # (setting, n) -> method\n",
    "        best_ari = {}   # (setting, n) -> method\n",
    "        \n",
    "        for y_setting in y_settings:\n",
    "            for n in sample_sizes:\n",
    "                # Determine applicable methods for this setting\n",
    "                if y_setting in ['Y1', 'Y2']:  # Continuous\n",
    "                    applicable_methods = ['CKDR-$m^*$', 'CKDR', 'RS-ES'] if y_setting == 'Y1' else ['CKDR-$m^*$', 'CKDR']\n",
    "                else:  # Discrete\n",
    "                    applicable_methods = ['CKDR-$m^*$', 'CKDR', 'Amalgam']\n",
    "                \n",
    "                # Find best distance (minimum)\n",
    "                valid_dist_values = []\n",
    "                for method in applicable_methods:\n",
    "                    key = (method, n, y_setting)\n",
    "                    if key in all_results and all_results[key]['dist_mean'] != '--':\n",
    "                        valid_dist_values.append((all_results[key]['dist_mean'], method))\n",
    "                \n",
    "                if valid_dist_values:\n",
    "                    min_dist = min(valid_dist_values, key=lambda x: x[0])\n",
    "                    best_dist[(y_setting, n)] = min_dist[1]\n",
    "                \n",
    "                # Find best ARI (maximum)\n",
    "                valid_ari_values = []\n",
    "                for method in applicable_methods:\n",
    "                    key = (method, n, y_setting)\n",
    "                    if key in all_results and all_results[key]['ari_mean'] != '--':\n",
    "                        valid_ari_values.append((all_results[key]['ari_mean'], method))\n",
    "                \n",
    "                if valid_ari_values:\n",
    "                    max_ari = max(valid_ari_values, key=lambda x: x[0])\n",
    "                    best_ari[(y_setting, n)] = max_ari[1]\n",
    "        \n",
    "        return best_dist, best_ari\n",
    "    \n",
    "    best_dist, best_ari = find_best_values_final()\n",
    "    \n",
    "    latex_lines = []\n",
    "    \n",
    "    # Table header\n",
    "    latex_lines.append(\"\\\\begin{table}[htbp]\")\n",
    "    latex_lines.append(\"\\\\centering\")\n",
    "    latex_lines.append(\"\\\\caption{Simulation Results: Subspace Distance and ARI}\")\n",
    "    latex_lines.append(\"\\\\label{tab:simulation_final}\")\n",
    "    latex_lines.append(\"\\\\begin{tabular}{llccccccc}\")\n",
    "    latex_lines.append(\"\\\\toprule\")\n",
    "    \n",
    "    # Column headers (switched: Setting first, then Method)\n",
    "    header1 = \"Setting & Method & \\\\multicolumn{3}{c}{Subspace Distance $\\\\times 100$} & \\\\multicolumn{3}{c}{ARI $\\\\times 100$} \\\\\\\\\"\n",
    "    header2 = \"& & $n=200$ & $n=500$ & $n=1000$ & $n=200$ & $n=500$ & $n=1000$ \\\\\\\\\"\n",
    "    latex_lines.append(header1)\n",
    "    latex_lines.append(\"\\\\cmidrule(lr){3-5} \\\\cmidrule(lr){6-8}\")\n",
    "    latex_lines.append(header2)\n",
    "    latex_lines.append(\"\\\\midrule\")\n",
    "    \n",
    "    # Setting specifications: (setting, label, applicable_methods)\n",
    "    setting_specs = [\n",
    "        ('Y1', '(I)', ['CKDR-$m^*$', 'CKDR', 'RS-ES']),\n",
    "        ('Y2', '(II)', ['CKDR-$m^*$', 'CKDR', 'RS-ES']),\n",
    "        ('Y3', '(III)', ['CKDR-$m^*$', 'CKDR', 'Amalgam']),\n",
    "        ('Y4', '(IV)', ['CKDR-$m^*$', 'CKDR', 'Amalgam'])\n",
    "    ]\n",
    "    \n",
    "    # Generate table body\n",
    "    for y_setting, setting_label, applicable_methods in setting_specs:\n",
    "        for i, method_name in enumerate(applicable_methods):\n",
    "            # Setting label (with multirow for first row)\n",
    "            if i == 0:\n",
    "                setting_cell = f\"\\\\multirow{{3}}{{*}}{{{setting_label}}}\"\n",
    "            else:\n",
    "                setting_cell = \"\"\n",
    "            \n",
    "            row_data = [setting_cell, method_name]\n",
    "            \n",
    "            # Subspace distances for all sample sizes\n",
    "            for n in sample_sizes:\n",
    "                key = (method_name, n, y_setting)\n",
    "                if key in all_results and all_results[key]['dist_mean'] != '--':\n",
    "                    res = all_results[key]\n",
    "                    is_best = best_dist.get((y_setting, n)) == method_name\n",
    "                    formatted = format_result(res['dist_mean'], res['dist_se'], is_best)\n",
    "                else:\n",
    "                    formatted = \"--\"\n",
    "                row_data.append(formatted)\n",
    "            \n",
    "            # ARI scores for all sample sizes\n",
    "            for n in sample_sizes:\n",
    "                key = (method_name, n, y_setting)\n",
    "                if key in all_results and all_results[key]['ari_mean'] != '--':\n",
    "                    res = all_results[key]\n",
    "                    is_best = best_ari.get((y_setting, n)) == method_name\n",
    "                    formatted = format_result(res['ari_mean'], res['ari_se'], is_best)\n",
    "                else:\n",
    "                    formatted = \"--\"\n",
    "                row_data.append(formatted)\n",
    "            \n",
    "            latex_lines.append(\" & \".join(row_data) + \" \\\\\\\\\")\n",
    "        \n",
    "        # Add midrule after each setting except the last\n",
    "        if y_setting != setting_specs[-1][0]:\n",
    "            latex_lines.append(\"\\\\midrule\")\n",
    "    \n",
    "    # Table footer\n",
    "    latex_lines.append(\"\\\\bottomrule\")\n",
    "    latex_lines.append(\"\\\\end{tabular}\")\n",
    "    latex_lines.append(\"\\\\end{table}\")\n",
    "    \n",
    "    return \"\\n\".join(latex_lines)\n",
    "\n",
    "# Generate the final custom table\n",
    "final_table = generate_final_custom_table()\n",
    "\n",
    "print(\"FINAL CUSTOM TABLE:\")\n",
    "print(\"-\" * 50)\n",
    "print(final_table)\n",
    "\n",
    "# Save the final table\n",
    "with open(\"results/tables/simulation_final_table.tex\", \"w\") as f:\n",
    "    f.write(final_table)\n",
    "\n",
    "print(\"\\\\n\\\\nFinal custom table saved to 'simulation_final_table.tex'!\")\n",
    "print(\"\\\\nThis design shows:\")\n",
    "print(\"- CKDR methods: All 4 settings (I-IV) with multirow\")\n",
    "print(\"- RS-ES: Only settings (I-II) for continuous responses\") \n",
    "print(\"- Amalgam: Only settings (III-IV) for discrete responses\")\n",
    "print(\"- Optimal values are boldfaced within each setting\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
